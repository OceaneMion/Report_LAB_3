{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline to execute RepeatModeler2 + EDTA --> MCHelper --> RepeatMasker (with the help of Alba Marino)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEs were identified through RepeatModeler2 and EDTA. Both tools generate comprehensive libraries of TEs, which may include redundant sequences. All isolated libraries were clustered through CD-Hit est (-d 0 -aS 0.98 -c 0.95 -G 0 -g 1 -b 500), and redundant sequences were filtered out through MCHelper using a minimum percentage of identity of 95%, and 98% coverage. (-outfmt 6 -perc_identity 95). We used a semi-automatic model in MCHelper to avoid having to verify detected TEs one by one.\n",
    "Once repeats were identified, they were annotated with RepeatMasker (-xsmall). \n",
    "To do so, we used a  pipeline designed by Alba Marino, a Phd Student of the lab (See code below). We used it separately for each P. destructans isolates and outgroup. The TE libraries from all P. destructans were then merged. The final TE annotations were realized with the merged P. destructans TE library using RepeatMasker. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# TE annotation pipeline\n",
    "\n",
    "# TO DO\n",
    "# add help message\n",
    "# add vm mode for softwares running in docker\n",
    "# change docker with singularity\n",
    "\n",
    "# Usage for a complete run (consensi discovery, automatic curation, genome annotation):\n",
    "# ./script.sh --species Drosophila_melanogaster --output ~/TEannotation_pipeline/TEannotation_benchmarking/results --threads 6 --run-dnapt2x --reads ~/TEannotation_pipeline/Drosophila_pectinifera_sample.fastq.gz --genome-size 1000000 --run-rm2 --run-edta --assembly ~/TEannotation_pipeline/GCA_000001215.4_sample.fa --run-mchelper --busco-lineage diptera --container-mode\n",
    "\n",
    "#############################\n",
    "# TO EDIT\n",
    "# Fill up the variables with programs full paths. If a program is in $PATH or running in Docker replace the path with \"\"\n",
    "\n",
    "RM2_PATH=\"\"\n",
    "DNAPT_PATH=/bigvol/alba/bin/pipeline_dnapipe/\n",
    "RM_PATH=\"\"\n",
    "EDTA_PATH=/bigvol/alba/bin/EDTA-2.0.1/\n",
    "MCHELPER_PATH=/bigvol/alba/bin/MCHelper/\n",
    "CONDA_PATH=${HOME}/miniconda3/\n",
    "#############################\n",
    "# DO NOT EDIT BELOW THIS LINE\n",
    "\n",
    "set -e\n",
    "\n",
    "THREADS=1\n",
    "SAMPLING_SIZE=\"0.25\"\n",
    "\n",
    "while [[ $# -gt 0 ]]; do\n",
    "\tcase $1 in\n",
    "\t\t--use-rm2-output) # use previous RM2 result instead of running RM2 from scratch (optional) - supply RM2 output directory previously generated\n",
    "\t\tRM2_OUTPUT=\"$2\"\n",
    "\t\tshift # past argument\n",
    "\t\tshift # past value\n",
    "\t\t;;\n",
    "\t\t--species) # MANDATORY argument for species name: used to name the parent directory with all the analyses outputs and as files prefix\n",
    "\t\tSPECIES=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--assembly) # MANDATORY argument for assembly name\n",
    "\t\tASSEMBLY=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--reads) # fastq file (mandatory if --run-dnapt2x is used)\n",
    "\t\tREADS=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--output) # MANDATORY argument for main output directory\n",
    "\t\tOUT=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--threads) # number of threads to use (optional; default 1)\n",
    "\t\tTHREADS=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--run-rm2) # run RM2 from scratch (optional)\n",
    "\t\tRUN_RM2=\"1\"\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--use-dnapt2x-output) # use previous dnaPT contigs instead of running dnaPT2x from scratch (optional) - supply dnaPipeTE directory previously generated\n",
    "\t\tDNAPT2X_OUTPUT=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--run-dnapt2x) # run dnaPT2X form scratch (optional)\n",
    "\t\tRUN_DNAPT2X=\"1\"\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--genome-size)\n",
    "\t\tGENOME_SIZE=\"$2\" # supply genome size for dnaPT (mandatory if --run-dnapt2x is used)\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--sampling-size) # coverage used by dnaPT (optional)\n",
    "\t\tSAMPLING_SIZE=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--run-edta) # run EDTA from scratch (optional)\n",
    "\t\tRUN_EDTA=\"1\"\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--use-edta-output) # use previous EDTA result instead of running it from scratch (optional) - supply EDTA directory previously generated\n",
    "\t\tEDTA_OUTPUT=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--run-mchelper) # run automated curation of all produced libraries altogether (optional)\n",
    "\t\tRUN_MCHELPER=\"1\"\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--busco-lineage) # choose the busco dataset (all lowercase) used by MCHelper for false positive detection (mandatory if --run-mchelper is used) - see https://busco-data.ezlab.org/v5/data/lineages/ for available lineages\n",
    "\t\tBUSCO_LINEAGE=\"$2\"\n",
    "\t\tshift\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--run-mask) # run RepeatMasker with the final library (optional)\n",
    "\t\tRUN_MASK=\"1\"\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\t\t--container-mode) # use this option if RepeatModeler2 and RepeatMasker are used in the te-tools docker image\n",
    "\t\tCONTAINER_MODE=\"1\"\n",
    "\t\tshift\n",
    "\t\t;;\n",
    "\tesac\n",
    "done\n",
    "\n",
    "# handle missing mandatory arguments\n",
    "\n",
    "if [[ ! -v SPECIES ]] || [[ ! -v OUT ]]; then\n",
    "\techo \"Either --species or --output are missing\"\n",
    "\texit 1\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_DNAPT2X ]] && [[ ! -v GENOME_SIZE ]]; then\n",
    "\techo \"Please supply --genome-size to run dnaPipeTE\"\n",
    "\texit 1\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_DNAPT2X ]] && [[ ! -v READS ]]; then\n",
    "\techo \"Please supply --reads to run dnaPipeTE\"\n",
    "\texit 1\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_RM2 ]] || [[ -v RUN_EDTA ]] || [[ -v RUN_MASK ]] && [[ ! -v ASSEMBLY ]]; then\n",
    "\techo \"Please supply --assembly for TE discovery, automated curation, and/or masking\"\n",
    "\texit 1\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_MCHELPER ]] && [[ ! -v BUSCO_LINEAGE ]]; then\n",
    "\techo \"Please supply --busco-lineage to run MCHelper\"\n",
    "\texit 1\n",
    "fi\n",
    "\n",
    "# set environment variables\n",
    "\n",
    "OUT_SP=${OUT}/${SPECIES}\n",
    "\n",
    "if [[ -v ASSEMBLY ]]; then\n",
    "\n",
    "\tBASENAME_ASSEMBLY=$(basename ${ASSEMBLY})\n",
    "\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_MCHELPER ]] || [[ -v RUN_EDTA ]]; then\n",
    "\n",
    "\tsource ${CONDA_PATH}/etc/profile.d/conda.sh\n",
    "\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_EDTA ]] || [[ -v EDTA_OUTPUT ]]; then\n",
    "\n",
    "\tseqkit replace -p '.+' -r 'ctg_{nr}' $ASSEMBLY > ${ASSEMBLY}_rename.fasta\n",
    "\tRENAMED_ASSEMBLY=$(readlink -f ${ASSEMBLY}_rename.fasta) # genome with reduced headers to use with EDTA\n",
    "\tBASENAME_RENAMED_ASSEMBLY=$(basename ${RENAMED_ASSEMBLY})\n",
    "\n",
    "fi\n",
    "\n",
    "# Set up te-tools container if --vm-mode is on\n",
    "\n",
    "#if [[ -v VM_MODE ]]; then\n",
    "\n",
    "#\techo \"RepeatModeler2 and/or RepeatMasker will be run inside docker container\"\n",
    "#\tsingularity exec dfam-tetools-latest.sif\n",
    "#\tdocker stop $(docker ps -a -q) && docker rm $(docker ps -a -q)\n",
    "#\tdocker run --name tetools -d -i -t dfam/tetools\n",
    "#\tdocker cp $ASSEMBLY tetools:/opt/src/\n",
    "#\tdocker exec -it tetools bash\n",
    "#\tBuildDatabase -name ${SPECIES} -engine ncbi $ASSEMBLY\n",
    "#\tRepeatModeler -engine ncbi -threads $THREADS -database ${RM2_OUTPUT}/${SPECIES}\n",
    "#\tRM2_LIB=$(readlink -f ${SPECIES}\\-families.fa)\n",
    "\n",
    "#fi\n",
    "\n",
    "# TE discovery step\n",
    "\n",
    "## RM2 submodule: obtain de novo families from RepeatModeler2\n",
    "\n",
    "if [ \"$RUN_RM2\" = \"1\" ] && [ ! -v VM_MODE ]; then\n",
    "\n",
    "\tRM2_OUTPUT=${OUT_SP}/RepeatModeler2\n",
    "\tmkdir -p $RM2_OUTPUT\n",
    "\techo \"Running RepeatModeler2\"\n",
    "\t\"${RM2_PATH}\"BuildDatabase -name ${RM2_OUTPUT}/${SPECIES} -engine ncbi $ASSEMBLY\n",
    "\t(\n",
    "\tcd $RM2_OUTPUT\n",
    "\t\"${RM2_PATH}\"RepeatModeler -engine ncbi -threads $THREADS -LTRStruct -database ${RM2_OUTPUT}/${SPECIES}\n",
    "\tRM2_LIB=$(readlink -f ${SPECIES}\\-families.fa)\n",
    "\t)\n",
    "\n",
    "elif [ \"$RUN_RM2\" = \"1\" ] && [ -v VM_MODE ]; then\n",
    "\n",
    "\techo \"Running RepeatModeler2 in te-tools container\"\n",
    "\n",
    "# run RM2 in container\n",
    "\n",
    "else\n",
    "\n",
    "\techo \"Skipping RepeatModeler2\"\n",
    "\n",
    "fi\n",
    "\n",
    "# RM2 check: *families.fa should exist if one of the two arguments was used\n",
    "\n",
    "if [[ -v RUN_RM2 ]] || [[ -v RM2_OUTPUT ]]; then\n",
    "\n",
    "\tif [[ ! -f ${RM2_OUTPUT}/${SPECIES}\\-families.fa ]]; then\n",
    "\n",
    "\t\techo \"Could not find RepeatModeler2 families at ${RM2_OUTPUT}\"\n",
    "\t\texit 1\n",
    "\n",
    "\telse\n",
    "\n",
    "\t\tRM2_LIB=$(readlink -f ${RM2_OUTPUT}/${SPECIES}\\-families.fa)\n",
    "\n",
    "\tfi\n",
    "fi\n",
    "\n",
    "## dnaPipeTE submodule: run 2rounds of dnaPipeTE and extract the dnaPipeTE contigs generated by the 2nd round (\"quick & clean\")\n",
    "\n",
    "if [ \"$RUN_DNAPT2X\" = \"1\" ]; then\n",
    "\n",
    "\tDNAPT2X_OUTPUT=${OUT_SP}/dnaPipeTE2x\n",
    "\tmkdir -p ${DNAPT2X_OUTPUT}\n",
    "\techo \"Running dnaPipeTE 2x module\"\n",
    "\n",
    "\t(\n",
    "\t\tABS_DNAPT2X_OUTPUT=$(readlink -f $DNAPT2X_OUTPUT)\n",
    "\t\tABS_READS=$(readlink -f $READS)\n",
    "\t\tACC_NUM=$(basename ${READS%fastq.gz})\n",
    "\t\tcd $DNAPT_PATH && snakemake all --use-conda -j $THREADS -C genome_size=$GENOME_SIZE sampling_size=$SAMPLING_SIZE out_dir=${ABS_DNAPT2X_OUTPUT} short_reads=$ABS_READS species=$SPECIES acc_num=${ACC_NUM}\n",
    "\t)\n",
    "\n",
    "else\n",
    "\n",
    "\techo \"Skipping dnaPipeTE 2x module\"\n",
    "\n",
    "fi\n",
    "\n",
    "## dnaPipeTE output check: a dnaPipeTE output should exist if one of the two arguments was used \n",
    "\n",
    "if [[ -v RUN_DNAPT2X ]] || [[ -v DNAPT2X_OUTPUT ]]; then\n",
    "\n",
    "\tif [[ ! -f ${DNAPT2X_OUTPUT}/final_dnapipete_output/Trinity.fasta ]]; then\n",
    "\n",
    "\t\techo \"Could not find dnaPipeTE contigs at ${DNAPT2X_OUTPUT}/final_dnapipete_output/\"\n",
    "\t\texit 1\n",
    "\n",
    "\telse\n",
    "\n",
    "\t\tDNAPT2X_LIB=$(readlink -f ${DNAPT2X_OUTPUT}/final_dnapipete_output/Trinity.fasta)\n",
    "\n",
    "\tfi\n",
    "fi\n",
    "\n",
    "## EDTA submodule\n",
    "\n",
    "if [ \"$RUN_EDTA\" = \"1\" ]; then\n",
    "\n",
    "\tEDTA_OUTPUT=${OUT_SP}/EDTA\n",
    "\tmkdir -p ${EDTA_OUTPUT}\n",
    "\techo \"Running EDTA\"\n",
    "\tconda activate EDTA\n",
    "\t(\n",
    "\t\tcd $EDTA_OUTPUT\n",
    "\t\t\"${EDTA_PATH}\"EDTA.pl --genome $RENAMED_ASSEMBLY --threads $THREADS\n",
    "\t)\n",
    "\tconda deactivate\n",
    "\n",
    "else\n",
    "\n",
    "\techo \"Skipping EDTA module\"\n",
    "\n",
    "fi\n",
    "\n",
    "## EDTA output check: a EDTA output should exist if one of the two arguments was used\n",
    "\n",
    "if [[ -v RUN_EDTA ]] || [[ -v EDTA_OUTPUT ]]; then\n",
    "\n",
    "\tif [[ ! -f \"${EDTA_OUTPUT}\"/\"${BASENAME_RENAMED_ASSEMBLY}\".mod.EDTA.TElib.fa ]]; then\n",
    "\n",
    "\t\techo \"Could not find EDTA output at ${EDTA_OUTPUT}\"\n",
    "\t\texit 1\n",
    "\n",
    "\telse\n",
    "\n",
    "\t\tEDTA_LIB=$(readlink -f \"${EDTA_OUTPUT}\"/\"${BASENAME_RENAMED_ASSEMBLY}\".mod.EDTA.TElib.fa)\n",
    "\tfi\n",
    "fi\n",
    "\n",
    "# Concatenate libraries and handle consensi duplicates in case of pipeline rerun\n",
    "# (output from one module is not added to mergelibs.fa if families from the same tool are already present\n",
    "\n",
    "LIBS_OUTPUT=${OUT_SP}/mergedlibs_precuration\n",
    "mkdir -p ${LIBS_OUTPUT}\n",
    "\n",
    "if [[ -v RUN_RM2 ]] || [[ -v RM2_OUTPUT ]]; then\n",
    "\n",
    "\tif [[ -f ${LIBS_OUTPUT}/mergedlibs.fa ]] && grep -q \"RM2_\" ${LIBS_OUTPUT}/mergedlibs.fa; then\n",
    "\n",
    "\t\techo -e \"${RM2_LIB} is not being added to ${LIBS_OUTPUT}/mergedlibs.fa, as families from RepeatModeler2 are already in there.\\n\\nIf instead you want to replace them, remove sequences with 'RM2_' prefix from mergedlibs.fa and append ${RM2_LIB} to it, then delete ${MCHELPER_OUTPUT} if needed and rerun the pipeline with --run-mchelper option.\"\n",
    "\n",
    "\telse\n",
    "\n",
    "\t\tsed 's/>/>RM2_/g' $RM2_LIB >> ${LIBS_OUTPUT}/mergedlibs.fa # add tool prefix to seqid\n",
    "\tfi\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_DNAPT2X ]] || [[ -v DNAPT2X_OUTPUT ]]; then\n",
    "\n",
    "\tif [[ -f ${LIBS_OUTPUT}/mergedlibs.fa ]] && grep -q \"dnaPT_\" ${LIBS_OUTPUT}/mergedlibs.fa; then\n",
    "\n",
    "\t\techo -e \"${DNAPT2X_LIB} is not being added to ${LIBS_OUTPUT}/mergedlibs.fa, as dnaPipeTE contigs are already in there.\\n\\nIf instead you want to replace them, remove sequences with 'dnaPT_' prefix from mergedlibs.fa and append ${DNAPT2X_LIB} to it, then delete ${MCHELPER_OUTPUT} if needed and rerun the pipeline with --run-mchelper option.\"\n",
    "\n",
    "\telse\n",
    "\n",
    "\t\tsed 's/>/>dnaPT_/g' $DNAPT2X_LIB | sed 's/>.*/&#Unknown/' >> ${LIBS_OUTPUT}/mergedlibs.fa\n",
    "\tfi\n",
    "fi\n",
    "\n",
    "if [[ -v RUN_EDTA ]] || [[ -v EDTA_OUTPUT ]]; then\n",
    "\n",
    "\tif [[ -f ${LIBS_OUTPUT}/mergedlibs.fa ]] && grep -q \"EDTA_\" ${LIBS_OUTPUT}/mergedlibs.fa; then\n",
    "\n",
    "\t\techo -e \"${EDTA_LIB} is not being added to ${LIBS_OUTPUT}/mergedlibs.fa, as families from EDTA are already in there.\\n\\nIf instead you want to replace them, remove sequences with 'EDTA_' prefix from mergedlibs.fa and append ${EDTA_LIB} to it, then delete ${MCHELPER_OUTPUT} if needed and rerun the pipeline with --run-mchelper option.\"\n",
    "\n",
    "\telse\n",
    "\n",
    "\t\tsed 's/>/>EDTA_/g' $EDTA_LIB >> ${LIBS_OUTPUT}/mergedlibs.fa\n",
    "\n",
    "\tfi\n",
    "fi\n",
    "\n",
    "\n",
    "# Libraries curation step: run MCHelper\n",
    "\n",
    "if [ \"$RUN_MCHELPER\" = \"1\" ]; then\n",
    "\n",
    "\tMCHELPER_OUTPUT=${OUT_SP}/MCHelper\n",
    "\tmkdir -p ${MCHELPER_OUTPUT}\n",
    "\tBUSCO_OUTPUT=${OUT_SP}/busco_profile\n",
    "\tmkdir -p ${BUSCO_OUTPUT}\n",
    "\techo \"Running MCHelper\"\n",
    "\tconda activate MCHelper\n",
    "\n",
    "## download busco hmm profiles\n",
    "\n",
    "\twget -O ${BUSCO_OUTPUT}/lineages.html https://busco-data.ezlab.org/v5/data/lineages/\n",
    "\tTARNAME=$(grep $BUSCO_LINEAGE ${BUSCO_OUTPUT}/lineages.html | cut -d'\"' -f2)\n",
    "\tABS_BUSCO_PREF=${BUSCO_OUTPUT}/${BUSCO_LINEAGE}\n",
    "\twget -O ${ABS_BUSCO_PREF}.tar.gz https://busco-data.ezlab.org/v5/data/lineages/${TARNAME} \n",
    "\ttar -xf ${ABS_BUSCO_PREF}.tar.gz -C $BUSCO_OUTPUT\n",
    "\tcat ${ABS_BUSCO_PREF}_odb10/hmms/*hmm > ${ABS_BUSCO_PREF}.hmm && rm -r ${ABS_BUSCO_PREF}.tar.gz ${ABS_BUSCO_PREF}_odb10\n",
    "\n",
    "\n",
    "\tpython3 \"${MCHELPER_PATH}\"MCHelper.py -r A -t $THREADS -l ${LIBS_OUTPUT}/mergedlibs.fa -o $MCHELPER_OUTPUT -g $ASSEMBLY --input_type fasta -b ${ABS_BUSCO_PREF}.hmm -a F\n",
    "\n",
    "\tconda deactivate\n",
    "\n",
    "else\n",
    "\n",
    "\techo \"Skipping MCHelper module\"\n",
    "\n",
    "fi\n",
    "\n",
    "# Masking step: use curated library to mask the genome assembly\n",
    "\n",
    "if [ \"$RUN_MASK\" = \"1\" ]; then\n",
    "\n",
    "\tMCHELPER_OUTPUT=${OUT_SP}/MCHelper\n",
    "\tif [[ -f ${MCHELPER_OUTPUT}/curated_sequences_NR.fa ]]; then\n",
    "\n",
    "\t\tRM_OUTPUT=${OUT_SP}/RepeatMasker\n",
    "\t\tmkdir -p ${RM_OUTPUT}\n",
    "\t\t(\n",
    "\t\t\tcd $RM_OUTPUT\n",
    "\t\t\techo \"Running RepeatMasker with ${MCHELPER_OUTPUT}/curated_sequences_NR.fa\"\n",
    "\t\t\t\"${RM_PATH}\"RepeatMasker -lib ${MCHELPER_OUTPUT}/curated_sequences_NR.fa -a -gff -pa $THREADS $ASSEMBLY\n",
    "\t\t)\n",
    "\telse\n",
    "\n",
    "\t\techo \"No library to mask with at ${MCHELPER_OUTPUT}\"\n",
    "\t\texit 1\n",
    "\n",
    "\tfi\n",
    "\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To loop on multiple genomes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/bin/bash\n",
    "\n",
    "# Automatically run TEannot pipeline from a reference table\n",
    "# NOTE: If you want to add or remove a pipeline brick, directly change the arguments in the bash commands of this script. Note that the change will apply in the same way to all the selected assemblies. Only exception is dnaPipeTE which can be run only if reads are available (as per mapfile).\n",
    "\n",
    "# Requirements:\n",
    "## sratoolkit should be installed and in $PATH\n",
    "## 1. mapfile: a tab-separated table containing <genus_species> in 1st column, <SRaccession> in 2nd column, <assemblysize> in 3rd column. If SR is not available fill in NA.\n",
    "## 2. all the assemblies for which we want to run the pipeline in the same directory and named as <genus_species_genome.fasta>\n",
    "## 3. the TEannot script.sh to run\n",
    "\n",
    "# usage: bash auto_run_teannot.sh 14 leotiomycetes\n",
    "## Arguments in order: mapfile name, number of threads, busco lineage to be used by MCHelper for false positive filtering \n",
    "\n",
    "for GENOME in *_modbasecalling.fasta; do\n",
    "\n",
    "\tSPECIES=${GENOME%_Dorado_modbasecalling.fasta}\n",
    "\tSPECIES=${SPECIES#filtered_hypo_}\n",
    "\n",
    "#\tif grep -Fwq \"$SPECIES\" $1; then\n",
    "\n",
    "#\t\tSRA=$(grep $SPECIES $1 | cut -f2)\n",
    "#\t\tGS=$(grep $SPECIES $1 | cut -f3)\n",
    "\n",
    "#\t\tif [ $SRA = \"NA\" ]; then\n",
    "\n",
    "#\t\t\techo \"Annotating TEs for $SPECIES without dnaPipeTE: reads not available\"\n",
    "\t\t\t#change here settings to run with the pipeline; can't add dnapt2x options here\n",
    "#\t\t\tbash /bigvol/alba/bin/TEannot_script_correct.sh --species $SPECIES --output ${PWD}/TEannotation_results --threads $2 --run-edta --assembly ${PWD}/$GENOME --use-rm2-output ${PWD}/TEannotation_results/${SPECIES}/RepeatModeler2 --run-mchelper --busco-lineage $3 --run-mask\n",
    "\n",
    "#\t\telse\n",
    "\n",
    "\t\t\techo \"Annotating TEs for $SPECIES with all the required options\"\n",
    "\t\t\t# The following commands fetch reads, convert to zipped fastq and rename if needed: comment them if dnapt2x is not run by script.sh!\n",
    "#\t\t\tmkdir tmpfastq\n",
    "#\t\t\t(\n",
    "#\t\t\t\tcd tmpfastq\n",
    "#\t\t\t\tprefetch $SRA --max-size 100GB -f yes -p\n",
    "#\t\t\t\tfasterq-dump --outdir $PWD --mem 1G --split-3 --threads $THREADS --skip-technical ${SRA}/${SRA}.sra\n",
    "#\t\t\t\tpigz *fastq\n",
    "#\t\t\t\tCOUNT=$(ls ${SRA}.fastq.gz | wc -l)\n",
    "#\t\t\t\tif [ $COUNT = 1 ]; then mv ${SRA}.fastq.gz ${SRA}_1.fastq.gz; fi\n",
    "#\t\t\t)\n",
    "\n",
    "\t\t\t#change here settings to run with the pipeline\n",
    "bash /bigvol/alba/bin/TEannot_script_correct.sh --species $SPECIES --output ${PWD}/TEannotation_results --threads $1 --run-edta --assembly ${PWD}/$GENOME --run-mchelper --run-rm2 --run-mask --busco-lineage $2 # --run-dnapt2x --reads ${PWD}/tmpfastq/${SRA}_1.fastq.gz --genome-size $GS\n",
    "#\t\t\tmv tmpfastq/* dropfastq/ && rm -r tmpfastq\n",
    "\n",
    "\n",
    "\n",
    "#\t\techo \"$SPECIES is not in the mapfile. Skipping...\"\n",
    "\n",
    "#\tfi\n",
    "\n",
    "\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UcjgpPDOSEq"
   },
   "source": [
    "* Repeat masker will output a .align file that contain the alignment between the consensus TEs sequences identify by RepeatMasker and our actual TEs sequences from our *P.destructans* assemblies.  \n",
    "  \n",
    "* From the .align file we have metric such as Kimura divergence.\n",
    "Kimura divergence allows estimating evolutionary divergence between TE sequences and their respective identified consensus sequence.\n",
    "\n",
    "* RepeatMasker use the following formula to calculate Kimura divergence: K = -1/2 ln(1-2p -q)-1/4ln(1-2q) with p as the number of transitions (A→G or C→T), and q as the proportion of transversions (A→T, A→C, G→T, G→ C).\n",
    "\n",
    "* RepeatMasker uses a CpG adjusted Kimura divergence, where two transitions at a CpG site are counted as a single event, and one transition at a CpG site is counted as 1/10th of a standard transition. Regarding, transversions they are counted normally at CpG sites. This adjustment is made to account for the hypermutability of CpG due to methylation, which can lead to an overestimation of divergence time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aIogefRYa9Ly"
   },
   "source": [
    "## Obtain a table with TEs family, start, end position, contig, and kimura divergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Pc228OGanyV"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# List to stock contigs, start position...\n",
    "contigs = []\n",
    "starts = []\n",
    "ends = []\n",
    "families = []\n",
    "kimura_values = []\n",
    "\n",
    "# Ouverture et lecture du fichier (LOOP avec * pour Gd* )\n",
    "with open('filtered_hypo_Gd267_Dorado_modbasecalling.fasta.align', 'r') as file:\n",
    "\tlines = file.readlines()\n",
    "\tfor line in lines:\n",
    "    \t# Recherche de la ligne contenant le contig, la position de départ et la position de fin\n",
    "    \tmatch = re.search(r'(\\w+)\\s+(\\d+)\\s+(\\d+)\\s+\\((\\d+)\\)\\s+(\\w+)', line)\n",
    "    \tif match:\n",
    "        \tcontig = match.group(1)\n",
    "        \tstart = int(match.group(2))\n",
    "        \tend = int(match.group(3))\n",
    "        \tfamily_temp = match.group(5)  # Famille temporaire\n",
    "\n",
    "        \tcontigs.append(contig)\n",
    "        \tstarts.append(start)\n",
    "        \tends.append(end)\n",
    "        \tfamilies.append(family_temp)  # Ajout de la famille temporaire\n",
    "\n",
    "    \t# Recherche de la famille d'éléments transposables après le #\n",
    "    \tif '#' in line:\n",
    "        \tfamily = line.split('#')[1].split()[0]\n",
    "        \tif family_temp in families:\n",
    "            \tindex = families.index(family_temp)\n",
    "            \tfamilies[index] = family  # Remplacement de la famille temporaire par la famille réelle\n",
    "\n",
    "    \t# Recherche de la valeur de Kimura\n",
    "    \tif 'Kimura (with divCpGMod)' in line:\n",
    "        \tkimura_value = float(line.split('=')[1].strip())\n",
    "        \tkimura_values.append(kimura_value)\n",
    "\n",
    "# Création du tableau\n",
    "table = list(zip(contigs, starts, ends, families, kimura_values))\n",
    "\n",
    "# Affichage du tableau sans les en-têtes\n",
    "for contig, start, end, family, kimura in table:\n",
    "\tprint(f\"{contig:<15} {start:<10} {end:<10} {family:<30} {kimura:<15}\") ### ICI MODIFIER POUR STOCKER DIRECT DANS UN .TXT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNtxyS8vbNv8"
   },
   "source": [
    "## Sort by TEs families (in column 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvuVhWqIbTNQ"
   },
   "outputs": [],
   "source": [
    "sort -k4 test.txt >> sorted_Gd267.txt (## FAIRE EN FOR LOOP AUSSI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NYf8XcZobbSi"
   },
   "source": [
    "## Histogram of kimura divergence for each TEs families (Rstudio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1QTnhM2j9gi"
   },
   "outputs": [],
   "source": [
    "library(ggplot2)\n",
    "library(tidyr)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "\n",
    "# Define the working directory\n",
    "setwd(\"/home/stagiaire/Documents/R_script_table/Age_TEs\")\n",
    "\n",
    "# Get the list of files in the directory\n",
    "file_list <- list.files(pattern = \"*.txt\")\n",
    "\n",
    "# Define lineage mapping\n",
    "lineage1_files <- c(\"sorted_Gd293.txt\", \"sorted_Gd1111.txt\", \"sorted_Gd2407.txt\", \"sorted_Gd442.txt\", \"sorted_Gd994.txt\", \"sorted_Gd4985.txt\")\n",
    "lineage2_files <- c(\"sorted_Gd45.txt\", \"sorted_Gd614.txt\", \"sorted_Gd708.txt\", \"sorted_Gd2185.txt\", \"sorted_Gd4986.txt\")\n",
    "outgroup_file <- \"sorted_Gd267.txt\"\n",
    "\n",
    "# Function to combine data for each lineage\n",
    "combine_data <- function(files) {\n",
    "  combined_data <- data.frame()\n",
    "  for (file in files) {\n",
    "    data <- read.table(file, header = FALSE, col.names = c(\"Contig\", \"Start\", \"End\", \"Class\", \"Value\"))\n",
    "    combined_data <- rbind(combined_data, data)\n",
    "  }\n",
    "  return(combined_data)\n",
    "}\n",
    "\n",
    "# Combine data for each lineage\n",
    "lineage1_data <- combine_data(lineage1_files)\n",
    "lineage2_data <- combine_data(lineage2_files)\n",
    "outgroup_data <- combine_data(outgroup_file)\n",
    "\n",
    "\n",
    "# Function to create plot for a combined dataset\n",
    "create_plot <- function(data, y_limit, title, show_legend = FALSE) {\n",
    "  data_grouped <- data %>%\n",
    "    filter(!is.na(Value) & Value >= 0 & Value <= 60) %>%\n",
    "    group_by(Class)\n",
    "\n",
    "  p <- ggplot(data_grouped, aes(x = Value, fill = Class)) +\n",
    "    geom_histogram(position = \"stack\", binwidth = 1) +\n",
    "    labs(x = \"Kimura divergence (CpG adjusted)\", y = \"Nb of TEs\", title = title) +\n",
    "    ylim(0, y_limit) + # Set y-axis limit\n",
    "    xlim(0, 60) # Set x-axis limit\n",
    "\n",
    "  if (show_legend) {\n",
    "    p <- p + guides(fill = guide_legend(title = \"Class\"))\n",
    "  } else {\n",
    "    p <- p + guides(fill = FALSE) # Hide the legend\n",
    "  }\n",
    "\n",
    "  return(p)\n",
    "}\n",
    "\n",
    "# Define y-axis limits\n",
    "y_limits <- c(lineage1 = 20000, lineage2 = 20000, outgroup = 20000)\n",
    "\n",
    "# Create plots for each lineage\n",
    "lineage1_plot <- create_plot(lineage1_data, y_limits[\"lineage1\"], \"Lineage 1\")\n",
    "lineage2_plot <- create_plot(lineage2_data, y_limits[\"lineage2\"], \"Lineage 2\")\n",
    "outgroup_plot <- create_plot(outgroup_data, y_limits[\"outgroup\"], \"Outgroup\")\n",
    "\n",
    "# Display the plots with the legend in the fourth column\n",
    "grid.arrange(lineage1_plot, lineage2_plot, outgroup_plot, ncol = 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Genome wide TE coverage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AJOUTER LE CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contig wide TE coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AJOUTER LE CODE AVEC BEDTOOL COVERAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setwd(\"C:/Users/ocean/Downloads\")\n",
    "\n",
    "# Load necessary libraries\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "library(gridExtra)\n",
    "\n",
    "# Read the CSV file\n",
    "data <- read.delim(\"contig_TEs_final(2).csv\", header = TRUE, sep=\",\")\n",
    "\n",
    "# Rename columns for clarity (adjust these names as needed)\n",
    "colnames(data)[c(2,3,6)] <- c(\"Legend\", \"name\", \"value\")\n",
    "\n",
    "# Function to filter unique contig names and reorder by value\n",
    "filter_unique_contigs_and_reorder <- function(df) {\n",
    "  df <- df %>%\n",
    "    group_by(name) %>%\n",
    "    filter(row_number() == 1) %>%\n",
    "    ungroup() %>%\n",
    "    arrange(desc(value))\n",
    "  return(df)\n",
    "}\n",
    "\n",
    "# Define colors for each category in Legend\n",
    "colors <- c(\"1\" = \"#FF5733\", \"2\" = \"#3377FF\", \"Outgroup\" = \"#9ACD32\")\n",
    "\n",
    "# Create separate plots for 'h' and 'm', with unique contig names and ordered by value\n",
    "plot_h <- data %>%\n",
    "  filter_unique_contigs_and_reorder() %>%\n",
    "  ggplot(aes(x = reorder(name, -value), y = value, fill = Legend)) +  # Use reorder for ordering\n",
    "  geom_bar(stat = \"identity\", position = position_dodge(width = 0.9), color = \"black\") +\n",
    "  facet_wrap(~ Legend, ncol = 1, scales = \"free_x\") +\n",
    "  scale_x_discrete(expand = c(0, 0)) +\n",
    "  scale_y_continuous(expand = c(0, 0), limits = NULL, name = \"TE coverage (%)\") +  # Y-axis label for the first plot\n",
    "  scale_fill_manual(values = colors) +  # Use manual scale for fill colors\n",
    "  theme_minimal() +\n",
    "  theme(\n",
    "    axis.text.x = element_blank(),\n",
    "    axis.ticks.x = element_blank(),\n",
    "    panel.grid.major.x = element_blank(),\n",
    "    panel.grid.minor.x = element_blank(),\n",
    "    panel.spacing = unit(0.1, \"lines\")\n",
    "  ) +\n",
    "  labs(title = expression(paste(\"TE coverage (%) in \", italic(\"P. destructans\"), \" and outgroup contigs\")), x = NULL, y = NULL)\n",
    "\n",
    "\n",
    "# Arrange and display plots in two rows\n",
    "grid.arrange(plot_h, nrow = 1)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNrRN5lhGmqC74jPR0U/yxS",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
