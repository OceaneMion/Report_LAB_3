{"cells":[{"cell_type":"markdown","metadata":{"id":"foZRvQjOcZbS"},"source":["# Pipeline to execute RepeatModeler2 + EDTA --> MCHelper --> RepeatMasker\n","(performed with Alba Marino)"]},{"cell_type":"markdown","metadata":{"id":"ZUF8kvAPcZbU"},"source":["TEs were identified through RepeatModeler2 and EDTA. Both tools generate comprehensive libraries of TEs, which may include redundant sequences. All isolated libraries were clustered through CD-Hit est (-d 0 -aS 0.98 -c 0.95 -G 0 -g 1 -b 500), and redundant sequences were filtered out through MCHelper using a minimum percentage of identity of 95%, and 98% coverage. (-outfmt 6 -perc_identity 95). We used a semi-automatic model in MCHelper to avoid having to verify detected TEs one by one.\n","Once repeats were identified, they were annotated with RepeatMasker (-xsmall).\n","To do so, we used a  pipeline designed by Alba Marino, a Phd Student of the lab (See code below). We used it separately for each P. destructans isolates and outgroup. The TE libraries from all *P. destructans* were then merged. The final TE annotations were realized with the merged *P. destructans* TE library using RepeatMasker."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JOm_TaExcZbV"},"outputs":[],"source":["#!/bin/bash\n","\n","# TE annotation pipeline\n","\n","# TO DO\n","# add help message\n","# add vm mode for softwares running in docker\n","# change docker with singularity\n","\n","# Usage for a complete run (consensi discovery, automatic curation, genome annotation):\n","# ./script.sh --species Drosophila_melanogaster --output ~/TEannotation_pipeline/TEannotation_benchmarking/results --threads 6 --run-dnapt2x --reads ~/TEannotation_pipeline/Drosophila_pectinifera_sample.fastq.gz --genome-size 1000000 --run-rm2 --run-edta --assembly ~/TEannotation_pipeline/GCA_000001215.4_sample.fa --run-mchelper --busco-lineage diptera --container-mode\n","\n","#############################\n","# TO EDIT\n","# Fill up the variables with programs full paths. If a program is in $PATH or running in Docker replace the path with \"\"\n","\n","RM2_PATH=\"\"\n","DNAPT_PATH=/bigvol/alba/bin/pipeline_dnapipe/\n","RM_PATH=\"\"\n","EDTA_PATH=/bigvol/alba/bin/EDTA-2.0.1/\n","MCHELPER_PATH=/bigvol/alba/bin/MCHelper/\n","CONDA_PATH=${HOME}/miniconda3/\n","#############################\n","# DO NOT EDIT BELOW THIS LINE\n","\n","set -e\n","\n","THREADS=1\n","SAMPLING_SIZE=\"0.25\"\n","\n","while [[ $# -gt 0 ]]; do\n","\tcase $1 in\n","\t\t--use-rm2-output) # use previous RM2 result instead of running RM2 from scratch (optional) - supply RM2 output directory previously generated\n","\t\tRM2_OUTPUT=\"$2\"\n","\t\tshift # past argument\n","\t\tshift # past value\n","\t\t;;\n","\t\t--species) # MANDATORY argument for species name: used to name the parent directory with all the analyses outputs and as files prefix\n","\t\tSPECIES=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--assembly) # MANDATORY argument for assembly name\n","\t\tASSEMBLY=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--reads) # fastq file (mandatory if --run-dnapt2x is used)\n","\t\tREADS=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--output) # MANDATORY argument for main output directory\n","\t\tOUT=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--threads) # number of threads to use (optional; default 1)\n","\t\tTHREADS=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--run-rm2) # run RM2 from scratch (optional)\n","\t\tRUN_RM2=\"1\"\n","\t\tshift\n","\t\t;;\n","\t\t--use-dnapt2x-output) # use previous dnaPT contigs instead of running dnaPT2x from scratch (optional) - supply dnaPipeTE directory previously generated\n","\t\tDNAPT2X_OUTPUT=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--run-dnapt2x) # run dnaPT2X form scratch (optional)\n","\t\tRUN_DNAPT2X=\"1\"\n","\t\tshift\n","\t\t;;\n","\t\t--genome-size)\n","\t\tGENOME_SIZE=\"$2\" # supply genome size for dnaPT (mandatory if --run-dnapt2x is used)\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--sampling-size) # coverage used by dnaPT (optional)\n","\t\tSAMPLING_SIZE=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--run-edta) # run EDTA from scratch (optional)\n","\t\tRUN_EDTA=\"1\"\n","\t\tshift\n","\t\t;;\n","\t\t--use-edta-output) # use previous EDTA result instead of running it from scratch (optional) - supply EDTA directory previously generated\n","\t\tEDTA_OUTPUT=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--run-mchelper) # run automated curation of all produced libraries altogether (optional)\n","\t\tRUN_MCHELPER=\"1\"\n","\t\tshift\n","\t\t;;\n","\t\t--busco-lineage) # choose the busco dataset (all lowercase) used by MCHelper for false positive detection (mandatory if --run-mchelper is used) - see https://busco-data.ezlab.org/v5/data/lineages/ for available lineages\n","\t\tBUSCO_LINEAGE=\"$2\"\n","\t\tshift\n","\t\tshift\n","\t\t;;\n","\t\t--run-mask) # run RepeatMasker with the final library (optional)\n","\t\tRUN_MASK=\"1\"\n","\t\tshift\n","\t\t;;\n","\t\t--container-mode) # use this option if RepeatModeler2 and RepeatMasker are used in the te-tools docker image\n","\t\tCONTAINER_MODE=\"1\"\n","\t\tshift\n","\t\t;;\n","\tesac\n","done\n","\n","# handle missing mandatory arguments\n","\n","if [[ ! -v SPECIES ]] || [[ ! -v OUT ]]; then\n","\techo \"Either --species or --output are missing\"\n","\texit 1\n","fi\n","\n","if [[ -v RUN_DNAPT2X ]] && [[ ! -v GENOME_SIZE ]]; then\n","\techo \"Please supply --genome-size to run dnaPipeTE\"\n","\texit 1\n","fi\n","\n","if [[ -v RUN_DNAPT2X ]] && [[ ! -v READS ]]; then\n","\techo \"Please supply --reads to run dnaPipeTE\"\n","\texit 1\n","fi\n","\n","if [[ -v RUN_RM2 ]] || [[ -v RUN_EDTA ]] || [[ -v RUN_MASK ]] && [[ ! -v ASSEMBLY ]]; then\n","\techo \"Please supply --assembly for TE discovery, automated curation, and/or masking\"\n","\texit 1\n","fi\n","\n","if [[ -v RUN_MCHELPER ]] && [[ ! -v BUSCO_LINEAGE ]]; then\n","\techo \"Please supply --busco-lineage to run MCHelper\"\n","\texit 1\n","fi\n","\n","# set environment variables\n","\n","OUT_SP=${OUT}/${SPECIES}\n","\n","if [[ -v ASSEMBLY ]]; then\n","\n","\tBASENAME_ASSEMBLY=$(basename ${ASSEMBLY})\n","\n","fi\n","\n","if [[ -v RUN_MCHELPER ]] || [[ -v RUN_EDTA ]]; then\n","\n","\tsource ${CONDA_PATH}/etc/profile.d/conda.sh\n","\n","fi\n","\n","if [[ -v RUN_EDTA ]] || [[ -v EDTA_OUTPUT ]]; then\n","\n","\tseqkit replace -p '.+' -r 'ctg_{nr}' $ASSEMBLY > ${ASSEMBLY}_rename.fasta\n","\tRENAMED_ASSEMBLY=$(readlink -f ${ASSEMBLY}_rename.fasta) # genome with reduced headers to use with EDTA\n","\tBASENAME_RENAMED_ASSEMBLY=$(basename ${RENAMED_ASSEMBLY})\n","\n","fi\n","\n","# Set up te-tools container if --vm-mode is on\n","\n","#if [[ -v VM_MODE ]]; then\n","\n","#\techo \"RepeatModeler2 and/or RepeatMasker will be run inside docker container\"\n","#\tsingularity exec dfam-tetools-latest.sif\n","#\tdocker stop $(docker ps -a -q) && docker rm $(docker ps -a -q)\n","#\tdocker run --name tetools -d -i -t dfam/tetools\n","#\tdocker cp $ASSEMBLY tetools:/opt/src/\n","#\tdocker exec -it tetools bash\n","#\tBuildDatabase -name ${SPECIES} -engine ncbi $ASSEMBLY\n","#\tRepeatModeler -engine ncbi -threads $THREADS -database ${RM2_OUTPUT}/${SPECIES}\n","#\tRM2_LIB=$(readlink -f ${SPECIES}\\-families.fa)\n","\n","#fi\n","\n","# TE discovery step\n","\n","## RM2 submodule: obtain de novo families from RepeatModeler2\n","\n","if [ \"$RUN_RM2\" = \"1\" ] && [ ! -v VM_MODE ]; then\n","\n","\tRM2_OUTPUT=${OUT_SP}/RepeatModeler2\n","\tmkdir -p $RM2_OUTPUT\n","\techo \"Running RepeatModeler2\"\n","\t\"${RM2_PATH}\"BuildDatabase -name ${RM2_OUTPUT}/${SPECIES} -engine ncbi $ASSEMBLY\n","\t(\n","\tcd $RM2_OUTPUT\n","\t\"${RM2_PATH}\"RepeatModeler -engine ncbi -threads $THREADS -LTRStruct -database ${RM2_OUTPUT}/${SPECIES}\n","\tRM2_LIB=$(readlink -f ${SPECIES}\\-families.fa)\n","\t)\n","\n","elif [ \"$RUN_RM2\" = \"1\" ] && [ -v VM_MODE ]; then\n","\n","\techo \"Running RepeatModeler2 in te-tools container\"\n","\n","# run RM2 in container\n","\n","else\n","\n","\techo \"Skipping RepeatModeler2\"\n","\n","fi\n","\n","# RM2 check: *families.fa should exist if one of the two arguments was used\n","\n","if [[ -v RUN_RM2 ]] || [[ -v RM2_OUTPUT ]]; then\n","\n","\tif [[ ! -f ${RM2_OUTPUT}/${SPECIES}\\-families.fa ]]; then\n","\n","\t\techo \"Could not find RepeatModeler2 families at ${RM2_OUTPUT}\"\n","\t\texit 1\n","\n","\telse\n","\n","\t\tRM2_LIB=$(readlink -f ${RM2_OUTPUT}/${SPECIES}\\-families.fa)\n","\n","\tfi\n","fi\n","\n","## dnaPipeTE submodule: run 2rounds of dnaPipeTE and extract the dnaPipeTE contigs generated by the 2nd round (\"quick & clean\")\n","\n","if [ \"$RUN_DNAPT2X\" = \"1\" ]; then\n","\n","\tDNAPT2X_OUTPUT=${OUT_SP}/dnaPipeTE2x\n","\tmkdir -p ${DNAPT2X_OUTPUT}\n","\techo \"Running dnaPipeTE 2x module\"\n","\n","\t(\n","\t\tABS_DNAPT2X_OUTPUT=$(readlink -f $DNAPT2X_OUTPUT)\n","\t\tABS_READS=$(readlink -f $READS)\n","\t\tACC_NUM=$(basename ${READS%fastq.gz})\n","\t\tcd $DNAPT_PATH && snakemake all --use-conda -j $THREADS -C genome_size=$GENOME_SIZE sampling_size=$SAMPLING_SIZE out_dir=${ABS_DNAPT2X_OUTPUT} short_reads=$ABS_READS species=$SPECIES acc_num=${ACC_NUM}\n","\t)\n","\n","else\n","\n","\techo \"Skipping dnaPipeTE 2x module\"\n","\n","fi\n","\n","## dnaPipeTE output check: a dnaPipeTE output should exist if one of the two arguments was used\n","\n","if [[ -v RUN_DNAPT2X ]] || [[ -v DNAPT2X_OUTPUT ]]; then\n","\n","\tif [[ ! -f ${DNAPT2X_OUTPUT}/final_dnapipete_output/Trinity.fasta ]]; then\n","\n","\t\techo \"Could not find dnaPipeTE contigs at ${DNAPT2X_OUTPUT}/final_dnapipete_output/\"\n","\t\texit 1\n","\n","\telse\n","\n","\t\tDNAPT2X_LIB=$(readlink -f ${DNAPT2X_OUTPUT}/final_dnapipete_output/Trinity.fasta)\n","\n","\tfi\n","fi\n","\n","## EDTA submodule\n","\n","if [ \"$RUN_EDTA\" = \"1\" ]; then\n","\n","\tEDTA_OUTPUT=${OUT_SP}/EDTA\n","\tmkdir -p ${EDTA_OUTPUT}\n","\techo \"Running EDTA\"\n","\tconda activate EDTA\n","\t(\n","\t\tcd $EDTA_OUTPUT\n","\t\t\"${EDTA_PATH}\"EDTA.pl --genome $RENAMED_ASSEMBLY --threads $THREADS\n","\t)\n","\tconda deactivate\n","\n","else\n","\n","\techo \"Skipping EDTA module\"\n","\n","fi\n","\n","## EDTA output check: a EDTA output should exist if one of the two arguments was used\n","\n","if [[ -v RUN_EDTA ]] || [[ -v EDTA_OUTPUT ]]; then\n","\n","\tif [[ ! -f \"${EDTA_OUTPUT}\"/\"${BASENAME_RENAMED_ASSEMBLY}\".mod.EDTA.TElib.fa ]]; then\n","\n","\t\techo \"Could not find EDTA output at ${EDTA_OUTPUT}\"\n","\t\texit 1\n","\n","\telse\n","\n","\t\tEDTA_LIB=$(readlink -f \"${EDTA_OUTPUT}\"/\"${BASENAME_RENAMED_ASSEMBLY}\".mod.EDTA.TElib.fa)\n","\tfi\n","fi\n","\n","# Concatenate libraries and handle consensi duplicates in case of pipeline rerun\n","# (output from one module is not added to mergelibs.fa if families from the same tool are already present\n","\n","LIBS_OUTPUT=${OUT_SP}/mergedlibs_precuration\n","mkdir -p ${LIBS_OUTPUT}\n","\n","if [[ -v RUN_RM2 ]] || [[ -v RM2_OUTPUT ]]; then\n","\n","\tif [[ -f ${LIBS_OUTPUT}/mergedlibs.fa ]] && grep -q \"RM2_\" ${LIBS_OUTPUT}/mergedlibs.fa; then\n","\n","\t\techo -e \"${RM2_LIB} is not being added to ${LIBS_OUTPUT}/mergedlibs.fa, as families from RepeatModeler2 are already in there.\\n\\nIf instead you want to replace them, remove sequences with 'RM2_' prefix from mergedlibs.fa and append ${RM2_LIB} to it, then delete ${MCHELPER_OUTPUT} if needed and rerun the pipeline with --run-mchelper option.\"\n","\n","\telse\n","\n","\t\tsed 's/>/>RM2_/g' $RM2_LIB >> ${LIBS_OUTPUT}/mergedlibs.fa # add tool prefix to seqid\n","\tfi\n","fi\n","\n","if [[ -v RUN_DNAPT2X ]] || [[ -v DNAPT2X_OUTPUT ]]; then\n","\n","\tif [[ -f ${LIBS_OUTPUT}/mergedlibs.fa ]] && grep -q \"dnaPT_\" ${LIBS_OUTPUT}/mergedlibs.fa; then\n","\n","\t\techo -e \"${DNAPT2X_LIB} is not being added to ${LIBS_OUTPUT}/mergedlibs.fa, as dnaPipeTE contigs are already in there.\\n\\nIf instead you want to replace them, remove sequences with 'dnaPT_' prefix from mergedlibs.fa and append ${DNAPT2X_LIB} to it, then delete ${MCHELPER_OUTPUT} if needed and rerun the pipeline with --run-mchelper option.\"\n","\n","\telse\n","\n","\t\tsed 's/>/>dnaPT_/g' $DNAPT2X_LIB | sed 's/>.*/&#Unknown/' >> ${LIBS_OUTPUT}/mergedlibs.fa\n","\tfi\n","fi\n","\n","if [[ -v RUN_EDTA ]] || [[ -v EDTA_OUTPUT ]]; then\n","\n","\tif [[ -f ${LIBS_OUTPUT}/mergedlibs.fa ]] && grep -q \"EDTA_\" ${LIBS_OUTPUT}/mergedlibs.fa; then\n","\n","\t\techo -e \"${EDTA_LIB} is not being added to ${LIBS_OUTPUT}/mergedlibs.fa, as families from EDTA are already in there.\\n\\nIf instead you want to replace them, remove sequences with 'EDTA_' prefix from mergedlibs.fa and append ${EDTA_LIB} to it, then delete ${MCHELPER_OUTPUT} if needed and rerun the pipeline with --run-mchelper option.\"\n","\n","\telse\n","\n","\t\tsed 's/>/>EDTA_/g' $EDTA_LIB >> ${LIBS_OUTPUT}/mergedlibs.fa\n","\n","\tfi\n","fi\n","\n","\n","# Libraries curation step: run MCHelper\n","\n","if [ \"$RUN_MCHELPER\" = \"1\" ]; then\n","\n","\tMCHELPER_OUTPUT=${OUT_SP}/MCHelper\n","\tmkdir -p ${MCHELPER_OUTPUT}\n","\tBUSCO_OUTPUT=${OUT_SP}/busco_profile\n","\tmkdir -p ${BUSCO_OUTPUT}\n","\techo \"Running MCHelper\"\n","\tconda activate MCHelper\n","\n","## download busco hmm profiles\n","\n","\twget -O ${BUSCO_OUTPUT}/lineages.html https://busco-data.ezlab.org/v5/data/lineages/\n","\tTARNAME=$(grep $BUSCO_LINEAGE ${BUSCO_OUTPUT}/lineages.html | cut -d'\"' -f2)\n","\tABS_BUSCO_PREF=${BUSCO_OUTPUT}/${BUSCO_LINEAGE}\n","\twget -O ${ABS_BUSCO_PREF}.tar.gz https://busco-data.ezlab.org/v5/data/lineages/${TARNAME}\n","\ttar -xf ${ABS_BUSCO_PREF}.tar.gz -C $BUSCO_OUTPUT\n","\tcat ${ABS_BUSCO_PREF}_odb10/hmms/*hmm > ${ABS_BUSCO_PREF}.hmm && rm -r ${ABS_BUSCO_PREF}.tar.gz ${ABS_BUSCO_PREF}_odb10\n","\n","\n","\tpython3 \"${MCHELPER_PATH}\"MCHelper.py -r A -t $THREADS -l ${LIBS_OUTPUT}/mergedlibs.fa -o $MCHELPER_OUTPUT -g $ASSEMBLY --input_type fasta -b ${ABS_BUSCO_PREF}.hmm -a F\n","\n","\tconda deactivate\n","\n","else\n","\n","\techo \"Skipping MCHelper module\"\n","\n","fi\n","\n","# Masking step: use curated library to mask the genome assembly\n","\n","if [ \"$RUN_MASK\" = \"1\" ]; then\n","\n","\tMCHELPER_OUTPUT=${OUT_SP}/MCHelper\n","\tif [[ -f ${MCHELPER_OUTPUT}/curated_sequences_NR.fa ]]; then\n","\n","\t\tRM_OUTPUT=${OUT_SP}/RepeatMasker\n","\t\tmkdir -p ${RM_OUTPUT}\n","\t\t(\n","\t\t\tcd $RM_OUTPUT\n","\t\t\techo \"Running RepeatMasker with ${MCHELPER_OUTPUT}/curated_sequences_NR.fa\"\n","\t\t\t\"${RM_PATH}\"RepeatMasker -lib ${MCHELPER_OUTPUT}/curated_sequences_NR.fa -a -gff -pa $THREADS $ASSEMBLY\n","\t\t)\n","\telse\n","\n","\t\techo \"No library to mask with at ${MCHELPER_OUTPUT}\"\n","\t\texit 1\n","\n","\tfi\n","\n","fi"]},{"cell_type":"markdown","metadata":{"id":"7A7JQF0YcZbX"},"source":["## For loop for multiple genomes"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"g1AwO-4FcZbY"},"outputs":[],"source":["#!/bin/bash\n","\n","# Automatically run TEannot pipeline from a reference table\n","# NOTE: If you want to add or remove a pipeline brick, directly change the arguments in the bash commands of this script. Note that the change will apply in the same way to all the selected assemblies. Only exception is dnaPipeTE which can be run only if reads are available (as per mapfile).\n","\n","# Requirements:\n","## sratoolkit should be installed and in $PATH\n","## 1. mapfile: a tab-separated table containing <genus_species> in 1st column, <SRaccession> in 2nd column, <assemblysize> in 3rd column. If SR is not available fill in NA.\n","## 2. all the assemblies for which we want to run the pipeline in the same directory and named as <genus_species_genome.fasta>\n","## 3. the TEannot script.sh to run\n","\n","# usage: bash auto_run_teannot.sh 14 leotiomycetes\n","## Arguments in order: mapfile name, number of threads, busco lineage to be used by MCHelper for false positive filtering\n","\n","for GENOME in *_modbasecalling.fasta; do\n","\n","\tSPECIES=${GENOME%_Dorado_modbasecalling.fasta}\n","\tSPECIES=${SPECIES#filtered_hypo_}\n","\n","#\tif grep -Fwq \"$SPECIES\" $1; then\n","\n","#\t\tSRA=$(grep $SPECIES $1 | cut -f2)\n","#\t\tGS=$(grep $SPECIES $1 | cut -f3)\n","\n","#\t\tif [ $SRA = \"NA\" ]; then\n","\n","#\t\t\techo \"Annotating TEs for $SPECIES without dnaPipeTE: reads not available\"\n","\t\t\t#change here settings to run with the pipeline; can't add dnapt2x options here\n","#\t\t\tbash /bigvol/alba/bin/TEannot_script_correct.sh --species $SPECIES --output ${PWD}/TEannotation_results --threads $2 --run-edta --assembly ${PWD}/$GENOME --use-rm2-output ${PWD}/TEannotation_results/${SPECIES}/RepeatModeler2 --run-mchelper --busco-lineage $3 --run-mask\n","\n","#\t\telse\n","\n","\t\t\techo \"Annotating TEs for $SPECIES with all the required options\"\n","\t\t\t# The following commands fetch reads, convert to zipped fastq and rename if needed: comment them if dnapt2x is not run by script.sh!\n","#\t\t\tmkdir tmpfastq\n","#\t\t\t(\n","#\t\t\t\tcd tmpfastq\n","#\t\t\t\tprefetch $SRA --max-size 100GB -f yes -p\n","#\t\t\t\tfasterq-dump --outdir $PWD --mem 1G --split-3 --threads $THREADS --skip-technical ${SRA}/${SRA}.sra\n","#\t\t\t\tpigz *fastq\n","#\t\t\t\tCOUNT=$(ls ${SRA}.fastq.gz | wc -l)\n","#\t\t\t\tif [ $COUNT = 1 ]; then mv ${SRA}.fastq.gz ${SRA}_1.fastq.gz; fi\n","#\t\t\t)\n","\n","\t\t\t#change here settings to run with the pipeline\n","bash /bigvol/alba/bin/TEannot_script_correct.sh --species $SPECIES --output ${PWD}/TEannotation_results --threads $1 --run-edta --assembly ${PWD}/$GENOME --run-mchelper --run-rm2 --run-mask --busco-lineage $2 # --run-dnapt2x --reads ${PWD}/tmpfastq/${SRA}_1.fastq.gz --genome-size $GS\n","#\t\t\tmv tmpfastq/* dropfastq/ && rm -r tmpfastq\n","\n","\n","\n","#\t\techo \"$SPECIES is not in the mapfile. Skipping...\"\n","\n","#\tfi\n","\n","\n","done"]},{"cell_type":"markdown","metadata":{"id":"6UcjgpPDOSEq"},"source":["* Repeat masker will output a .align file that contain the alignment between the consensus TEs sequences identify by RepeatMasker and our actual TEs sequences from our *P.destructans* assemblies.  \n","  \n","* From the .align file we have metric such as Kimura divergence.\n","Kimura divergence allows estimating evolutionary divergence between TE sequences and their respective identified consensus sequence.\n","\n","* RepeatMasker use the following formula to calculate Kimura divergence: K = -1/2 ln(1-2p -q)-1/4ln(1-2q) with p as the number of transitions (A→G or C→T), and q as the proportion of transversions (A→T, A→C, G→T, G→ C).\n","\n","* RepeatMasker uses a CpG adjusted Kimura divergence, where two transitions at a CpG site are counted as a single event, and one transition at a CpG site is counted as 1/10th of a standard transition. Regarding, transversions they are counted normally at CpG sites. This adjustment is made to account for the hypermutability of CpG due to methylation, which can lead to an overestimation of divergence time.\n"]},{"cell_type":"markdown","metadata":{"id":"aIogefRYa9Ly"},"source":["## Obtain a table with TEs family, start, end position, contig, and kimura divergence from the .align files of RepeatMasker"]},{"cell_type":"code","source":["import os\n","import re\n","from glob import glob\n","\n","# Function to extract the isolate name from the folder\n","def extract_Gd_number(file_path):\n","    match = re.search(r'Gd(\\d+)_RMout_commonlib', file_path)\n","    if match:\n","        return match.group(1)\n","    else:\n","        return None\n","\n","# Function to process .align file, and create list to stock contigs,start,end position, type of TE families...\n","def process_file(file_path):\n","    contigs = []\n","    starts = []\n","    ends = []\n","    families = []\n","    kimura_values = []\n","\n","    with open(file_path, 'r') as file:\n","        lines = file.readlines()\n","        family_temp = ''\n","        for line in lines:\n","            match = re.search(r'(\\w+)\\s+(\\d+)\\s+(\\d+)\\s+\\((\\d+)\\)\\s+(\\w+)', line)\n","            if match:\n","                contig = match.group(1)\n","                start = int(match.group(2))\n","                end = int(match.group(3))\n","                family_temp = match.group(5)\n","\n","                contigs.append(contig)\n","                starts.append(start)\n","                ends.append(end)\n","                families.append(family_temp)\n","\n","            # Extract the family of TE from the file\n","            if '#' in line:\n","                family = line.split('#')[1].split()[0]\n","                if family_temp in families:\n","                    index = families.index(family_temp)\n","                    families[index] = family\n","\n","            # Extract the kimura divergence\n","            if 'Kimura (with divCpGMod)' in line:\n","                kimura_value = float(line.split('=')[1].strip())\n","                kimura_values.append(kimura_value)\n","\n","    # Create a table to stock the values\n","    table = list(zip(contigs, starts, ends, families, kimura_values))\n","\n","    # Extract isolate name from the path\n","    Gd_number = extract_Gd_number(file_path)\n","    if Gd_number is None:\n","        print(f\"Cannot extract Gd number from file path: {file_path}\")\n","        return\n","\n","    # Store the table in their respective folder\n","    output_filename = f'sorted_Gd{Gd_number}.txt'\n","    output_path = os.path.join(os.path.dirname(file_path), output_filename)\n","    with open(output_path, 'w') as output_file:\n","        for contig, start, end, family, kimura in table:\n","            output_file.write(f\"{contig:<15} {start:<10} {end:<10} {family:<30} {kimura:<15}\\n\")\n","\n","# Search for files matching the pattern\n","file_pattern = '/bigvol/omion/RMount_commonlib/Gd*_RMout_commonlib/filtered_hypo_Gd*_Dorado_modbasecalling.fasta.align'\n","files = glob(file_pattern)\n","\n","# Process each file found\n","for file in files:\n","    process_file(file)\n"],"metadata":{"id":"Umn42k6O6R3J"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Histogram of kimura divergence for each TEs families (Rstudio)"],"metadata":{"id":"8NBRLfC_erB8"}},{"cell_type":"code","source":["library(ggplot2)\n","library(tidyr)\n","library(dplyr)\n","library(gridExtra)\n","\n","# Define the working directory\n","setwd(\"/home/stagiaire/Documents/R_script_table/Age_TEs\")\n","\n","# Get the list of files in the directory\n","file_list <- list.files(pattern = \"*.txt\")\n","\n","# Define lineage mapping\n","lineage1_files <- c(\"sorted_Gd293.txt\", \"sorted_Gd1111.txt\", \"sorted_Gd2407.txt\", \"sorted_Gd442.txt\", \"sorted_Gd994.txt\", \"sorted_Gd4985.txt\")\n","lineage2_files <- c(\"sorted_Gd45.txt\", \"sorted_Gd614.txt\", \"sorted_Gd708.txt\", \"sorted_Gd2185.txt\", \"sorted_Gd4986.txt\")\n","outgroup_file <- \"sorted_Gd267.txt\"\n","\n","# Function to combine data for each lineage\n","combine_data <- function(files) {\n","  combined_data <- data.frame()\n","  for (file in files) {\n","    data <- read.table(file, header = FALSE, col.names = c(\"Contig\", \"Start\", \"End\", \"Class\", \"Value\"))\n","    combined_data <- rbind(combined_data, data)\n","  }\n","  return(combined_data)\n","}\n","\n","# Combine data for each lineage\n","lineage1_data <- combine_data(lineage1_files)\n","lineage2_data <- combine_data(lineage2_files)\n","outgroup_data <- combine_data(outgroup_file)\n","\n","\n","# Function to create plot for a combined dataset\n","create_plot <- function(data, y_limit, title, show_legend = FALSE) {\n","  data_grouped <- data %>%\n","    filter(!is.na(Value) & Value >= 0 & Value <= 60) %>%\n","    group_by(Class)\n","\n","  p <- ggplot(data_grouped, aes(x = Value, fill = Class)) +\n","    geom_histogram(position = \"stack\", binwidth = 1) +\n","    labs(x = \"Kimura divergence (CpG adjusted)\", y = \"Nb of TEs\", title = title) +\n","    ylim(0, y_limit) + # Set y-axis limit\n","    xlim(0, 60) # Set x-axis limit\n","\n","  if (show_legend) {\n","    p <- p + guides(fill = guide_legend(title = \"Class\"))\n","  } else {\n","    p <- p + guides(fill = FALSE) # Hide the legend\n","  }\n","\n","  return(p)\n","}\n","\n","# Define y-axis limits\n","y_limits <- c(lineage1 = 20000, lineage2 = 20000, outgroup = 20000)\n","\n","# Create plots for each lineage\n","lineage1_plot <- create_plot(lineage1_data, y_limits[\"lineage1\"], \"Lineage 1\")\n","lineage2_plot <- create_plot(lineage2_data, y_limits[\"lineage2\"], \"Lineage 2\")\n","outgroup_plot <- create_plot(outgroup_data, y_limits[\"outgroup\"], \"Outgroup\")\n","\n","# Display the plots with the legend in the fourth column\n","grid.arrange(lineage1_plot, lineage2_plot, outgroup_plot, ncol = 3)"],"metadata":{"id":"RnZ5RNlqerB-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9GoGmHg_cZba"},"source":["# Genome wide TE coverage"]},{"cell_type":"markdown","source":["To obtain the genome wide TE coverage, we need to perform severals steps.  \n","\n","1) Remove header of .out files (gff3 format)  \n","\n","2) Sort by contig, start and end position of TEs   \n","\n","3) Keep only column for contig, start, end position, type of TE (optionnal)\n","\n","4) Bedtool merge to merge overlapping TE\n","\n","5) Bedtool genomecov to have the global TE coverage accross the genomes of P.destructans\n","\n","You will find the bash script below:"],"metadata":{"id":"KRc5PX4r5lCx"}},{"cell_type":"code","source":["#!/bin/bash\n","\n","for file in /bigvol/omion/RMount_commonlib/Gd*_RMout_commonlib/filtered_hypo_Gd*_Dorado_modbasecalling.fasta.out; do\n","    gd_number=$(basename \"$file\" | grep -oP 'Gd\\d+')\n","    genome_file=\"/bigvol/omion/Analysis/03-TEs_families_content/contig_lenght/${gd_number}_contig_length.txt\"\n","\n","    # Get the directory of the input file\n","    output_dir=$(dirname \"$file\")\n","\n","    # Create the output filename\n","    output_file=\"${output_dir}/${gd_number}_coverage.txt\"\n","\n","    tail -n +4 \"$file\" |\n","    sort -k5,5 -k6,6n -k7,7n |\n","    awk '{print $5 \"\\t\" $6 \"\\t\" $7 \"\\t\" $11}' |\n","    bedtools merge -i - -c 4 -o distinct |\n","    bedtools genomecov -i - -g \"$genome_file\" > \"$output_file\"\n","\n","    echo \"Processed $gd_number. Output saved to $output_file\"\n","done\n"],"metadata":{"id":"KhCtnnDlvuM5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v8XuT0OEfO1t"},"source":["# Genome wide TE coverage (by classification of TEs)"]},{"cell_type":"code","source":["## Coverage by TE family\n","\n","import os\n","import re\n","from collections import defaultdict\n","\n","input_directory = '/bigvol/omion/Analysis/03-TEs_families_content/filtered'\n","output_directory = '/bigvol/omion/Analysis/03-TEs_families_content'\n","\n","# Output file path\n","output_file_path = os.path.join(output_directory, 'coverage_TEs_families.txt')\n","files = os.listdir(input_directory)\n","\n","\n","with open(output_file_path, 'w') as output_file:\n","    for filename in files:\n","        if filename.endswith('.out'):\n","\n","            match = re.search(r'(Gd\\d+)', filename) # Extract isolate name\n","            if match:\n","                sample_name = match.group(1)\n","            else:\n","                sample_name = \"Unknown\"\n","\n","            filepath = os.path.join(input_directory, filename)\n","\n","            # Store coverage by classification of TEs\n","            coverage_by_category = defaultdict(int)\n","\n","            # Calculate coverage\n","            with open(filepath, 'r') as file:\n","                for line in file:\n","                    columns = line.split()\n","                    if len(columns) >= 4:\n","                        start = int(columns[1])\n","                        end = int(columns[2])\n","                        category = columns[3]\n","                        coverage = end - start + 1\n","                        coverage_by_category[category] += coverage\n","\n","            # Write coverage for each classification\n","            for category, total_coverage in coverage_by_category.items():\n","                output_file.write(f\"{sample_name}\\t{category}\\t{total_coverage}\\n\")\n","\n","print(f\"Results have been written to {output_file_path}\")"],"metadata":{"id":"yK1DP0VHBSAZ"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":0}